# ======================================================================================================
# Variables
# ======================================================================================================

myAzureLocation="eastus"
myResourceGroup="cdd-cluster-rg"

myAvailabilitySetMaster="asMaster"
myAvailabilitySetWorker="asWorker"


myVnet="cdd-vnet"
mySubnet="cluster-snet"
myVmNicNsg="hdpVmNsg"

myOSImage="OpenLogic:CentOS:7.3:latest"
myVMSku="Standard_DS12"

myAdminUID="cddadmin"
myAdminRSASSHPubKey=<Path to SSH Public Key>

myImageVmName="hdpImageVm"
myImageVmPublicIp="hdpImageVmPip"
myImageVmNic="hdpImageVmNic"
myImageVmOsDiskName="$myImageVmName-osdisk"

myBaseHdpNodeOsImage="hdpNodeOsImage"

# az vm image list --offer CentOS --all --output table
# az vm list-sizes --location eastus --output table

# ======================================================================================================
# GENERAL STEPS
# ======================================================================================================

# G1) Create a resource group
# ======================================================================================================
az group create \
--name $myResourceGroup \
--location $myAzureLocation

# G2) Create a VNet and subnet
# ======================================================================================================
az network vnet create \
--resource-group $myResourceGroup \
--name $myVnet --address-prefix 10.13.0.0/16 \
--subnet-name $mySubnet --subnet-prefix 10.13.1.0/24

# G3) Create a NSG
# ======================================================================================================
az network nsg create \
--resource-group $myResourceGroup \
--name $myVmNicNsg

# G4) Create a NSG rule for SSH 
# ======================================================================================================
az network nsg rule create \
--resource-group $myResourceGroup \
--nsg-name  $myVmNicNsg \
--name SSH --priority 1000 --destination-port-range 22 --access allow

# G5) Create availability sets
# ======================================================================================================
az vm availability-set create -n $myAvailabilitySetMaster -g $myResourceGroup --platform-fault-domain-count 3 --platform-update-domain-count 3 &
az vm availability-set create -n $myAvailabilitySetWorker -g $myResourceGroup --platform-fault-domain-count 3 --platform-update-domain-count 10 

# ======================================================================================================
# HDP BASE VM IMAGE SPECIFIC - to be run on VM
# ======================================================================================================

# I1) Create NIC for the image VM
# ======================================================================================================
az network nic create \
  --resource-group $myResourceGroup \
  --name $myImageVmNic \
  --vnet-name $myVnet \
  --subnet $mySubnet \
  --network-security-group $myVmNicNsg \
  --internal-dns-name cdd \
  --public-ip-address ""

# I2) Create the image VM
# ======================================================================================================
az vm create \
--resource-group $myResourceGroup \
--name  $myImageVmName \
--admin-username $myAdminUID \
--ssh-key-value akhanolk_cb.pub \
--image $myOSImage \
--size $myVMSku \
--nics $myImageVmNic \
--os-disk-name $myImageVmOsDiskName

# I3) Apply the following configurations on the image VM as root
# ======================================================================================================

# I3.1. Install dependencies

yum -y install gdisk
yum -y install chrony
yum -y install nscd
yum install sssd realmd oddjob oddjob-mkhomedir adcli samba-common samba-common-tools krb5-workstation openldap-clients policycoreutils-python -y

# I3.2. Disable, stop firewalld/iptables

systemctl disable firewalld
systemctl stop firewalld
systemctl status firewalld

# I3.3. Enable, start chronyd

systemctl start chronyd
systemctl enable chronyd
systemctl status chronyd

# I3.4. Disable SELINUX

sed -i s/SELINUX=enforcing/SELINUX=disabled/g /etc/sysconfig/selinux

# sestatus will say enforcing until reboot
# With OpenLogic CentOS 7.3, I found that post reboot sestatus still said enforcing.
# Modified /etc/selinux/config that still showed as enforcing, and rebooted after which sestatus showed as disabled (prob a symlink issue)

# I3.5. Start, enable name service caching daemon

systemctl start nscd
systemctl enable nscd
systemctl status nscd

# I3.6. Disable transparenthugepage (memory optimizer)

# Note: This command had a redhat_ prefix in 6.x, in 7, the command is the same between RHEL and CentOS 7.x - as done below

# Immediate execution
echo never |sudo tee -a  /sys/kernel/mm/transparent_hugepage/enabled
echo never |sudo tee -a /sys/kernel/mm/transparent_hugepage/defrag

# For execution upon restart
echo 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' |sudo tee -a /etc/rc.local
echo 'echo never > /sys/kernel/mm/transparent_hugepage/defrag' |sudo tee -a /etc/rc.local


# I3.7. Other optimizations

# Some of these need to be tuned as needed

echo "vm.swappiness=1
net.ipv4.tcp_timestamps=0
net.ipv4.tcp_sack=1
net.core.netdev_max_backlog=250000
net.core.rmem_max=4194304
net.core.wmem_max=4194304
net.core.rmem_default=4194304
net.core.wmem_default=4194304
net.core.optmem_max=4194304
net.ipv4.tcp_rmem=4096 87380 4194304
net.ipv4.tcp_wmem=4096 65536 4194304
net.ipv4.tcp_low_latency=1
net.ipv4.tcp_adv_win_scale=1" |sudo tee -a /etc/sysctl.conf
sudo sysctl -p

# This concludes prep of the image VM;
# The next few steps cover creating an image from this VM

# ======================================================================================================
# CREATE IMAGE - run on machine with az cli
# ======================================================================================================

# C1. Deallocate (take a power nap)

az vm deallocate \
--resource-group $myResourceGroup \
--name $myImageVmName

# C2. Generalize

az vm generalize \
--resource-group $myResourceGroup \
--name $myImageVmName

# C3. Create image

az image create \
--resource-group $myResourceGroup \
--name $myBaseHdpNodeOsImage \
--source $myImageVmName


# ======================================================================================================
# PROVISION CLUSTER VMs - Management Node
# ======================================================================================================

# P1. Create management node

vmName="hdp-an01"
dataDiskName1=$vmName-data1
dataDiskName2=$vmName-mysql
dataDiskName3=$vmName-kdc
osDiskName=$vmName-osDisk
vmNic=$vmName-nic

az network nic create \
  --resource-group $myResourceGroup \
  --name $vmNic \
  --vnet-name $myVnet \
  --subnet $mySubnet \
  --network-security-group $myVmNicNsg \
  --public-ip-address "" 

az disk create -g $myResourceGroup -n $dataDiskName1 --size-gb 500 &
az disk create -g $myResourceGroup -n $dataDiskName2 --size-gb 500 &
az disk create -g $myResourceGroup -n $dataDiskName3 --size-gb 500 &


az vm create \
--resource-group $myResourceGroup \
--name $vmName \
--image $myBaseHdpNodeOsImage \
--admin-username akhanolk \
--ssh-key-value akhanolk_cb.pub \
--os-disk-name $osDiskName \
--public-ip-address "" \
--size $myVMSku \
--nics $vmNic  

az vm disk attach --disk $dataDiskName1 --resource-group $myResourceGroup --vm-name $vmName --lun 1 &
az vm disk attach --disk $dataDiskName2 --resource-group $myResourceGroup --vm-name $vmName --lun 2 &
az vm disk attach --disk $dataDiskName3 --resource-group $myResourceGroup --vm-name $vmName --lun 3

# ======================================================================================================
# PROVISION CLUSTER VMs - Edge Node
# ======================================================================================================

# P2. Create edge node

vmName="hdp-en01"
dataDiskName1=$vmName-data1
dataDiskName2=$vmName-data2
osDiskName=$vmName-osDisk
vmNic=$vmName-nic

az network nic create \
  --resource-group $myResourceGroup \
  --name $vmNic \
  --vnet-name $myVnet \
  --subnet $mySubnet \
  --network-security-group $myVmNicNsg \
  --public-ip-address "" &

az disk create -g $myResourceGroup -n $dataDiskName1 --size-gb 500 &
az disk create -g $myResourceGroup -n $dataDiskName2 --size-gb 500 


az vm create \
--resource-group $myResourceGroup \
--name $vmName \
--image $myBaseHdpNodeOsImage \
--admin-username akhanolk \
--ssh-key-value akhanolk_cb.pub \
--os-disk-name $osDiskName \
--public-ip-address "" \
--size $myVMSku \
--nics $vmNic  

az vm disk attach --disk $dataDiskName1 --resource-group $myResourceGroup --vm-name $vmName --lun 1 &
az vm disk attach --disk $dataDiskName2 --resource-group $myResourceGroup --vm-name $vmName --lun 2 


# ======================================================================================================
# PROVISION CLUSTER VMs - Master nodes
# ======================================================================================================

for i in 1 2 3
do
	vmName=hdp-mn0$i
	dataDiskName1=$vmName-data1
	dataDiskName2=$vmName-data2
	dataDiskName3=$vmName-data3
	osDiskName=$vmName-osDisk
	vmNic=$vmName-nic

	az network nic create --resource-group $myResourceGroup --name $vmNic --vnet-name $myVnet --subnet $mySubnet --network-security-group $myVmNicNsg --public-ip-address "" 
	az disk create -g $myResourceGroup -n $dataDiskName1 --size-gb 500 &
	az disk create -g $myResourceGroup -n $dataDiskName2 --size-gb 500 &
	az disk create -g $myResourceGroup -n $dataDiskName3 --size-gb 500 

	az vm create \
	--resource-group $myResourceGroup --name $vmName --image $myBaseHdpNodeOsImage \
	--admin-username akhanolk --ssh-key-value akhanolk_cb.pub --os-disk-name $osDiskName \
	--public-ip-address ""  --size $myVMSku --nics $vmNic  --availability-set asMaster

	az vm disk attach --disk $dataDiskName1 --resource-group $myResourceGroup --vm-name $vmName --lun 1 
	az vm disk attach --disk $dataDiskName2 --resource-group $myResourceGroup --vm-name $vmName --lun 2  
	az vm disk attach --disk $dataDiskName3 --resource-group $myResourceGroup --vm-name $vmName --lun 3

done

# ======================================================================================================
# PROVISION CLUSTER VMs - Worker nodes
# ======================================================================================================

for i in 1 2 3
do
	vmName=hdp-sn0$i
	dataDiskName1=$vmName-data1
	dataDiskName2=$vmName-data2
	dataDiskName3=$vmName-data3
	osDiskName=$vmName-osDisk
	vmNic=$vmName-nic

	az network nic create --resource-group $myResourceGroup --name $vmNic --vnet-name $myVnet --subnet $mySubnet --network-security-group $myVmNicNsg --public-ip-address "" 
	az disk create -g $myResourceGroup -n $dataDiskName1 --size-gb 500 &
	az disk create -g $myResourceGroup -n $dataDiskName2 --size-gb 500 &
	az disk create -g $myResourceGroup -n $dataDiskName3 --size-gb 500 

	az vm create \
	--resource-group $myResourceGroup --name $vmName --image $myBaseHdpNodeOsImage \
	--admin-username akhanolk --ssh-key-value akhanolk_cb.pub --os-disk-name $osDiskName \
	--public-ip-address ""  --size $myVMSku --nics $vmNic  --availability-set asWorker

	az vm disk attach --disk $dataDiskName1 --resource-group $myResourceGroup --vm-name $vmName --lun 1 
	az vm disk attach --disk $dataDiskName2 --resource-group $myResourceGroup --vm-name $vmName --lun 2  
	az vm disk attach --disk $dataDiskName3 --resource-group $myResourceGroup --vm-name $vmName --lun 3
done




az vm disk attach -g $myResourceGroup  --vm-name hdp-sn03 --disk hdp-sn03-data1 --lun 1 
az vm disk attach -g $myResourceGroup  --vm-name hdp-sn03 --disk hdp-sn03-data3 --lun 3 

